{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ynWO2HO-EokE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import cv2\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yz-NrYXErJlz"
      },
      "outputs": [],
      "source": [
        "def get_speed_wheel(image):\n",
        "    '''\n",
        "    extract the speed and the wheel from the image, the speed is represented by the number of white pixels in the speedometer and their intensity\n",
        "    the wheel is represented by the number of green pixels\n",
        "    both extracted values are normalized:\n",
        "    speed: (0, 1, 2, ..., 20)\n",
        "    wheel: (-10, -8, -7, -5, -4, -2, -1, 0, 1, 2, 4, 5, 7, 8, 10)\n",
        "    '''\n",
        "    speed_img = image[90:94,12:14]\n",
        "    w1 = np.all(speed_img > [240, 240, 240], axis=-1)\n",
        "    w2 = np.all(speed_img > [210, 210, 210], axis=-1)\n",
        "    w3 = np.all(speed_img > [180, 180, 180], axis=-1)\n",
        "    w4 = np.all(speed_img > [150, 150, 150], axis=-1)\n",
        "    w5 = np.all(speed_img > [120, 120, 120], axis=-1)\n",
        "    w6 = np.all(speed_img > [90, 90, 90], axis=-1)\n",
        "    w7 = np.all(speed_img > [60, 60, 60], axis=-1)\n",
        "    w8 = np.all(speed_img > [30, 30, 30], axis=-1)\n",
        "    speed1 = np.sum(w1)\n",
        "    speed2 = np.sum(w2)\n",
        "    speed3 = np.sum(w3)\n",
        "    speed4 = np.sum(w4)\n",
        "    speed5 = np.sum(w5)\n",
        "    speed6 = np.sum(w6)\n",
        "    speed7 = np.sum(w7)\n",
        "    speed8 = np.sum(w8)\n",
        "    speed = math.ceil((speed1 + speed2 + speed3 + speed4 + speed5 + speed6 + speed7 + speed8) / 2)\n",
        "    if speed > 20:\n",
        "        speed = 20 # (0, 1, 2, ..., 20)\n",
        "\n",
        "    wheel_image = image[86:92,36:60]\n",
        "    R, G, B = wheel_image[:, :, 0], wheel_image[:, :, 1], wheel_image[:, :, 2]\n",
        "    green_mask = (G > 250) & (R == 0) & (B == 0)\n",
        "    left_green = green_mask[:,:12]\n",
        "    right_green = green_mask[:,12:]\n",
        "    left_count = np.sum(left_green)\n",
        "    right_count = np.sum(right_green)\n",
        "    if left_count > 0 and right_count > 0:\n",
        "        print('ERR')\n",
        "    green_pixels = max(left_count, right_count)\n",
        "    wheel = math.ceil(green_pixels / 4) # (-10, -8, -7, -5, -4, -2, -1, 0, 1, 2, 4, 5, 7, 8, 10)\n",
        "    if right_count > 0:\n",
        "        wheel *= -1\n",
        "\n",
        "    return speed, wheel\n",
        "\n",
        "def highlight_track(image):\n",
        "    '''\n",
        "    This function removes red and green pixels from the image, removing curbs and grass and highlighting the track\n",
        "    '''\n",
        "    r, g, b = cv2.split(image)\n",
        "    mask_white_only = (r > 130) & (g > 130) & (b > 130)\n",
        "    mask_white = np.zeros_like(mask_white_only, dtype=bool)\n",
        "    mask_white[mask_white_only] = True\n",
        "\n",
        "    mask_diff_only = (np.abs(r - g) > 10) | (np.abs(r - b) > 10) | (np.abs(g - b) > 10)\n",
        "    mask_diff = np.zeros_like(mask_diff_only, dtype=bool)\n",
        "    mask_diff[mask_diff_only] = True\n",
        "    mask = mask_diff | mask_white\n",
        "\n",
        "    image[mask > 0] = [255, 255, 255]\n",
        "    image[mask == 0] = [0, 0, 0]\n",
        "    return image\n",
        "\n",
        "\n",
        "def delete_nears(edge_indices):\n",
        "    '''\n",
        "    This function deletes the near indices in the edge_indices list:\n",
        "    it is useful to avoid multiple detections of the same edge\n",
        "    (the nears pixels of an edge are detected needs to be counted as one edge)\n",
        "    '''\n",
        "    pred = -100\n",
        "    ret = []\n",
        "    for i in edge_indices:\n",
        "        if pred + 1 < i:\n",
        "            ret.append(i)\n",
        "        pred = i\n",
        "    return ret\n",
        "\n",
        "def get_car_position(black_track, edges):\n",
        "    '''\n",
        "    this function returns the position of the car respect to the track:\n",
        "    -1 if the car is on the left, 1 if the car is on the right, 0 if the car is at the center, -2 if the car is out of the track\n",
        "    black_track: the image of the track colored in black and everything else in white\n",
        "    edges: the edges of the track detected by the Canny algorithm\n",
        "    '''\n",
        "    height, width, _ = black_track.shape # 34,52\n",
        "\n",
        "    if not all(black_track[height - 1, int(width / 2)] == 0): # the car is out of the track\n",
        "        if all(black_track[height - 1, int(width / 2) + 3] == 0): # the car is near enough to the left border\n",
        "            return -1\n",
        "        elif all(black_track[height - 1, int(width / 2) - 3] == 0): # the car is near enough to the right border\n",
        "            return 1\n",
        "        else:\n",
        "            return -2 # the car is out of the track\n",
        "\n",
        "    edges_at_bottom_left = delete_nears(np.where(edges[height - 1, :int(width / 2)] > 0)[0])\n",
        "    edges_at_bottom_right = delete_nears(np.where(edges[height - 1, int(width / 2):] > 0)[0])\n",
        "    left_border = edges_at_bottom_left[-1] if len(edges_at_bottom_left) > 0 else 0\n",
        "    right_border = edges_at_bottom_right[0] + int(width / 2) if len(edges_at_bottom_right) > 0 else width\n",
        "\n",
        "    if left_border + 3 > width / 2:\n",
        "        return -1 # the car is on the left respect to the track\n",
        "    elif right_border - 3 < width / 2:\n",
        "        return 1 # the car is on the right respect to the track\n",
        "    else:\n",
        "        return 0 # the car is inside the track\n",
        "\n",
        "def find_edges_at_y(black_track, edges, y, position):\n",
        "    '''\n",
        "    this function returns the edges of the track at a certain y coordinate\n",
        "    black_track: the image of the track colored in black and everything else in white\n",
        "    edges: the edges of the track detected by the Canny algorithm\n",
        "    y: the y coordinate where to find the edges\n",
        "    position: the position of the car respect to the track\n",
        "    '''\n",
        "    height, width = edges.shape # 34,52\n",
        "\n",
        "    up_indices = delete_nears(np.where(edges[0, :] > 0)[0])\n",
        "    left_indices = delete_nears(np.where(edges[:, 0] > 0)[0])\n",
        "    right_indices = delete_nears(np.where(edges[:, width - 1] > 0)[0])\n",
        "\n",
        "    borders_at_y = delete_nears(np.where(edges[y, :] > 0)[0])\n",
        "\n",
        "    # we know that the car is inside the track\n",
        "    if len(borders_at_y) > 2:\n",
        "        # take the nearest borders on the right and the nearest on the left\n",
        "        borders_at_y_left = [elem for elem in borders_at_y if elem < (width / 2)]\n",
        "        borders_at_y_right = [elem for elem in borders_at_y if elem > (width / 2)]\n",
        "        return borders_at_y_left[-1], borders_at_y_right[0] # take the 2 nearest to the center\n",
        "\n",
        "    elif len(borders_at_y) < 2:\n",
        "        if len(right_indices) > 0 and len(left_indices) > 0: #one or more borders enters right and one or more borders enters left\n",
        "            if right_indices[0] > left_indices[0]: # the track goes from right-bottom to left-top\n",
        "                return -2, -2 # turn to left\n",
        "            else: # the track goes from left-bottom to right-top\n",
        "                return -1, -1 # turn to right\n",
        "        elif len(right_indices) > 0: #one or more borders enters right\n",
        "            return -1, -1 # turn to right\n",
        "        elif len(left_indices) > 0: #one or more borders enters left\n",
        "            return -2, -2 # turn to left\n",
        "        '''\n",
        "        if at a certain y there are less than 2 borders, and none of them are on the right or left, then there must be 3 borders entering down and 1 entering up\n",
        "        or 1 border entering down and 1 entering up\n",
        "        or 2 borders entering down and 0 entering up\n",
        "        '''\n",
        "        if len(up_indices) == 1:\n",
        "            up_index = up_indices[0]\n",
        "\n",
        "            if all(black_track[0, up_index - 3] == 0): # the track is on the left respect to the border\n",
        "                return -2, -2 # turn to left\n",
        "            else: # the track is on the right respect to the border\n",
        "                return -1, -1 # turn to right\n",
        "        else:\n",
        "            return None, None # going straight at the end of a curve (near to out of the track)\n",
        "    else:\n",
        "        return borders_at_y[0], borders_at_y[1]\n",
        "\n",
        "\n",
        "def discretize_state(state):\n",
        "    '''\n",
        "    this function discretize the state in order to use it as a key in the Q table\n",
        "    '''\n",
        "    zoom_state = state[20:60, 22:74]\n",
        "    h_t = highlight_track(zoom_state)\n",
        "    edges = cv2.Canny(h_t, threshold1=80, threshold2=120)\n",
        "\n",
        "    position = get_car_position(h_t, edges)\n",
        "    if position == -2: # the car is out of the track\n",
        "        return None\n",
        "\n",
        "    speed, wheel = get_speed_wheel(state)\n",
        "\n",
        "    points_ahead = [39, 14]\n",
        "    angles = []\n",
        "    for y in points_ahead:\n",
        "        y_a = y - 14\n",
        "        l1, r1 = find_edges_at_y(h_t, edges, y_a, position)\n",
        "        l2, r2 = find_edges_at_y(h_t, edges, y, position)\n",
        "\n",
        "        if None in (l1, r1, l2, r2):\n",
        "            return None\n",
        "        if -1 in (l2, r2):\n",
        "            angles.append(-0.9)\n",
        "            continue\n",
        "        elif -1 in (l1, r1):\n",
        "            angles.append(-0.8)\n",
        "            continue\n",
        "        elif -2 in (l2, r2):\n",
        "            angles.append(0.9)\n",
        "            continue\n",
        "        elif -2 in (l1, r1):\n",
        "            angles.append(0.8)\n",
        "            continue\n",
        "\n",
        "        angle_left = np.arctan2((l2 - l1), (y - y_a))\n",
        "        angle_right = np.arctan2((r2 - r1), (y - y_a))\n",
        "        track_direction = (angle_left + angle_right) / 2.0\n",
        "        a = round(track_direction, 2)\n",
        "        while(a * 100 % 5 != 0):\n",
        "            a = round(a + 0.01, 2)\n",
        "        a = float(a)\n",
        "        angles.append(a)\n",
        "\n",
        "    angles.append(speed)\n",
        "    angles.append(wheel)\n",
        "    angles.append(position)\n",
        "    return tuple(angles)#, edges# add to the angles info the speed info and wheel info\n",
        "\n",
        "\n",
        "def EpsGreedyPolicy(Q, env, state, epsilon):\n",
        "    if np.random.rand() < epsilon:\n",
        "        return env.action_space.sample()  # random action\n",
        "    else:\n",
        "        return np.argmax(Q[state])  # choose action with higher Q\n",
        "\n",
        "def RandomPolicy(env):\n",
        "    return env.action_space.sample()  # random action\n",
        "\n",
        "def GreedyPolicy(Q, state, env):\n",
        "    if state not in Q:\n",
        "        return env.action_space.sample()  # random action\n",
        "    return np.argmax(Q[state])  # choose action with higher Q\n",
        "\n",
        "def update_q_table(Q, state, action, reward, next_state, alpha, gamma):\n",
        "    best_next_action = np.argmax(Q[next_state])\n",
        "    td_target = reward + gamma * Q[next_state][best_next_action]\n",
        "    td_delta = td_target - Q[state][action]\n",
        "    Q[state][action] += alpha * td_delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GHw-PHuTpQ9Z"
      },
      "outputs": [],
      "source": [
        "def qlearn(Q, env, alpha, gamma, num_episodes, epsilon=0.9, min_epsilon=0.15):\n",
        "    for episode in range(num_episodes):\n",
        "        if (episode +1) % 200 == 0:\n",
        "            print(f\"Current reward: {evaluate(Q, env, gamma, policy='greedy')}\")\n",
        "        state, _ = env.reset()\n",
        "        state = (0.0, 0.0, 0, 0, 0) # initial state\n",
        "        truncated = terminated = False\n",
        "        for step in range(1000):\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "            if step < 45: # skip the first 45 steps to avoid the initial phase of zooming in the track\n",
        "                _, _, _, _, _ = env.step(0)\n",
        "                continue\n",
        "            action = EpsGreedyPolicy(Q, env, state, epsilon)\n",
        "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
        "\n",
        "            next_state = discretize_state(next_state)\n",
        "            if next_state is None: # out of track or limit case\n",
        "                next_state = ()\n",
        "                print('OUT')\n",
        "                reward = -100\n",
        "                truncated = True\n",
        "\n",
        "            update_q_table(Q, state, action, reward, next_state, alpha, gamma)\n",
        "            state = next_state\n",
        "\n",
        "        epsilon = epsilon * 0.9993\n",
        "        epsilon = max(epsilon, min_epsilon)\n",
        "        print(f\"Episode {episode + 1}/{num_episodes}, epsilon: {epsilon}, steps: {step + 1}/{1000}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rbl5iO-T9EsU"
      },
      "outputs": [],
      "source": [
        "def evaluate(Q, env, gamma, render=False, n_episodes=10, policy='random'):\n",
        "    \"\"\"Perform rollouts and compute the average discounted return.\"\"\"\n",
        "    sum_reward = 0.0\n",
        "    state, _ = env.reset()\n",
        "    state = (0.0, 0.0, 0, 0, 0) # initial state\n",
        "    ep = 0\n",
        "    truncated = terminated = False\n",
        "\n",
        "    step = 0\n",
        "    while True:\n",
        "        if truncated or terminated:\n",
        "            print(\"New episode\")\n",
        "            _, _ = env.reset()\n",
        "            state = (0.0, 0.0, 0, 0, 0)\n",
        "            ep += 1\n",
        "            step = 0\n",
        "            if ep >= n_episodes:\n",
        "                break\n",
        "        if step < 45:\n",
        "            _, _, terminated, truncated, _ = env.step(0)\n",
        "            step += 1\n",
        "            continue\n",
        "\n",
        "        if policy == 'greedy':\n",
        "            action = GreedyPolicy(Q, state, env)\n",
        "        else:\n",
        "            action = RandomPolicy(env)\n",
        "\n",
        "        state, reward, terminated, truncated, info = env.step(action)\n",
        "        state = discretize_state(state)\n",
        "        if state is None:\n",
        "            state = ()\n",
        "\n",
        "        step += 1\n",
        "        sum_reward += reward\n",
        "\n",
        "        if render:\n",
        "          if random.random() < 0.1:\n",
        "              print(\"state \" + str(state))\n",
        "              print(\"reward \" + str(reward))\n",
        "              print(\"truncated \" + str(truncated))\n",
        "              print(\"terminated \" + str(terminated))\n",
        "              print(\"step \" + str(step))\n",
        "              print(\"info \" + str(info))\n",
        "              print(\"action \" + str(actions[action]))\n",
        "              img = env.render()\n",
        "              show_frame(img)\n",
        "              time.sleep(0.4)\n",
        "              clear_output(wait=True)\n",
        "    return(sum_reward / n_episodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rxxQD3jHEPnQ"
      },
      "outputs": [],
      "source": [
        "alpha = 0.15  # Tasso di apprendimento\n",
        "gamma = 0.99  # Fattore di sconto\n",
        "epsilon = 1  # Probabilità di esplorazione # adjusted durinf learning\n",
        "num_episodes = 4000  # Numero di episodi di addestramento\n",
        "actions = {0: 'N', 1: 'L', 2: 'R', 3: 'A', 4: 'B'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1nPhH2PGDk3q"
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"CarRacing-v2\", domain_randomize=False, continuous=False, render_mode=\"rgb_array\")\n",
        "Q = defaultdict(lambda: np.zeros(env.action_space.n))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "''' load a previously trained Q table '''\n",
        "# Q_dict = pickle.load(open(\"QT/Q_table_2.pkl\", \"rb\"))\n",
        "# Q = defaultdict(lambda: np.zeros(env.action_space.n), Q_dict)\n",
        "# evaluate(Q, env, gamma, render=True, n_episodes=1, policy='random')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsCPWnWWFCcu",
        "outputId": "307eedf1-dfc2-4082-8a35-26c9d5b2ceb1"
      },
      "outputs": [],
      "source": [
        "avg = evaluate(Q, env, gamma, render=False, n_episodes=5, policy='random')\n",
        "print(avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8rt3847DmZc",
        "outputId": "88efb33d-ea64-4a23-ab87-d812a898faa5"
      },
      "outputs": [],
      "source": [
        "qlearn(Q, env, alpha, gamma, num_episodes, epsilon=epsilon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "b0zDWkwb-eUX",
        "outputId": "d17caca8-3578-416a-d4ad-39c5d3dd07bf"
      },
      "outputs": [],
      "source": [
        "avg = evaluate(Q, env, gamma, render=True, n_episodes=1, policy='greedy')\n",
        "print(avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_Unp0zfNl-_",
        "outputId": "eb805cbc-7230-4070-e19e-b29acb4c7713"
      },
      "outputs": [],
      "source": [
        "''' print the Q table '''\n",
        "# print(len(Q))\n",
        "# dict_speed = {}\n",
        "# for i, s in enumerate(Q):\n",
        "#     if i < 00:\n",
        "#         continue\n",
        "#     if i > 4000:\n",
        "#         break\n",
        "#     print(s)\n",
        "#     print(s[:2])\n",
        "#     if (len(s) <= 1):\n",
        "#         continue\n",
        "#     print(\"speed: \" + str(s[2]))\n",
        "#     print(\"wheel: \" + str(s[3]))\n",
        "#     print(\"pos: \" + str(s[4]))\n",
        "#     for j, a in enumerate(Q[s]):\n",
        "#         if j == 0:\n",
        "#             print(\"do nothing: \" + str(a))\n",
        "#         elif j == 1:\n",
        "#             print(\"steer right: \" + str(a))\n",
        "#         elif j == 2:\n",
        "#             print(\"steer left: \" + str(a))\n",
        "#         elif j == 3:\n",
        "#             print(\"accelerate: \" + str(a))\n",
        "#         elif j == 4:\n",
        "#             print(\"brake: \" + str(a))\n",
        "\n",
        "#     print('#####')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwMR_CNXM_1R"
      },
      "outputs": [],
      "source": [
        "''' save the Q table and the hyperparameters and results '''\n",
        "# Q_dict = dict(Q)\n",
        "# with open('QT/Q_table_13.pkl', 'wb') as f:\n",
        "#     pickle.dump(Q_dict, f)\n",
        "# with open('QT/hyperparameters_13.txt', 'w') as f:\n",
        "#     f.write(f\"alpha: {alpha}\\n\")\n",
        "#     f.write(f\"gamma: {gamma}\\n\")\n",
        "#     f.write(f\"epsilon: {epsilon}\\n\")\n",
        "#     f.write(f\"num_episodes: {num_episodes}\\n\")\n",
        "#     f.write(f\"max_steps: {max_steps}\\n\")\n",
        "#     f.write(f\"eps_min: {0.15}\\n\")\n",
        "#     f.write(f\"eps_decay: {0.9992}\\n\")\n",
        "#     f.write(f\"actions: {actions}\\n\")\n",
        "#     f.write(f\"angles_distances: {39, 14}\\n\")\n",
        "#     f.write(f\"range: 14\\n\")\n",
        "#     f.write(f\"zoom-size: 20,26; 22,74\\n\")\n",
        "#     f.write(f\"Q_table_size: {len(Q)}\\n\")\n",
        "#     f.write(f\"avg_reward: {evaluate(Q, env, gamma, render=False, n_episodes=15, policy='greedy')}\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
